{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片分类\n",
    "\n",
    "1. [介绍](#介绍)\n",
    "2. [运行环境](#运行环境)\n",
    "3. [预处理](#预处理)\n",
    "  1. [权限和环境变量](#权限和环境变量)\n",
    "  2. [准备数据](#准备数据)\n",
    "  3. [数据拆分](#数据拆分)\n",
    "4. [图像分类模型的微调](#图像分类模型的微调)\n",
    "  1. [训练参数](#训练参数)\n",
    "  2. [训练](#训练)\n",
    "5. [部署模型](#部署模型)\n",
    "  1. [创建模型](#创建模型)\n",
    "  2. [推理](#推理)\n",
    "    1. [创建终端节点配置](#创建终端节点配置) \n",
    "    2. [创建终端节点](#创建终端节点) \n",
    "    3. [进行推理](#进行推理) \n",
    "    4. [清理](#Clean-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍\n",
    "[参看原文](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-lst-format.ipynb)  \n",
    "欢迎来到图像分类算法训练的端到端示例。在这个演示中，我们将在迁移学习模式下使用Amazon-sagemaker图像分类算法来微调预先训练的模型（根据imagenet数据进行训练），以学习对新数据集进行分类。  \n",
    "我们需要通过一些先决步骤来设置环境，这些步骤包括权限、配置等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行环境\n",
    "Kernel 请选择 mxnet_p36。  \n",
    "本文在boto3 1.4.57和sagemaker 2.5.4下测试通过。不能使用sagemaker 1.xx版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3,sagemaker\n",
    "print(boto3.__version__)\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理\n",
    "### 权限和环境变量\n",
    "设置到AWS服务的链接和身份验证。包含三个部分：\n",
    "\n",
    "* 用于向学习和托管访问数据的角色。这将从用于启动笔记本的角色自动获取\n",
    "\n",
    "* 用于存储训练数据和模型的S3\n",
    "\n",
    "* Amazon sagemaker图像分类docker image，无需更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "#如果使用SageMaker的笔记本实例使用下一行\n",
    "role = get_execution_role()\n",
    "#如果使用自建的笔记本实例请自行获取Role，可从IAM控制台获取到\n",
    "#role = \"arn:aws-cn:iam::<<account id>>:role/service-role/AmazonSageMaker-ExecutionRole-20200430T124235\"\n",
    "\n",
    "bucket='<<your bucket>>' # 定义S3 bukcet，用于存放处理后的图片和训练模型\n",
    "\n",
    "training_image = retrieve('image-classification',boto3.Session().region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据\n",
    "这里没有使用原文的256 dataset，采用的是kaggle的[猫狗分类](https://www.kaggle.com/c/dogs-vs-cats/data?select=train.zip)。下载后按如下目录组织猫狗图片。\n",
    "```\n",
    "input_data\n",
    "├── class1\n",
    "│   ├── image001.jpg\n",
    "│   ├── image002.jpg\n",
    "│   └── ...\n",
    "├── class2\n",
    "│   ├── image001.jpg\n",
    "│   ├── image002.jpg\n",
    "│   └── ...\n",
    "└── classn\n",
    "    ├── image001.jpg\n",
    "    ├── image002.jpg\n",
    "    └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方式1、从官网下载\n",
    "[猫狗数据下载](https://www.kaggle.com/c/dogs-vs-cats/data?select=train.zip)，然后上传到NoteBook当前目录。请下载train.zip，不要选择Download All。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "unzip -q train.zip\n",
    "mv train cat-vs-dog\n",
    "mkdir -p cat-vs-dog/cat\n",
    "mkdir -p cat-vs-dog/dog\n",
    "mv cat-vs-dog/cat.*.jpg cat-vs-dog/cat/\n",
    "mv cat-vs-dog/dog.*.jpg cat-vs-dog/dog/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方式2、从已准备好的文件下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget -q -O cat-vs-dog.zip https://xxx/cat-vs-dog.zip\n",
    "unzip -q cat-vs-dog.zip\n",
    "#修改下行代码的第一个参数为实际目录\n",
    "mv cat-vs-dog-1000 cat-vs-dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p cat-vs-dog-val\n",
    "for i in cat-vs-dog/*; do\n",
    "    c=`basename $i`\n",
    "    mkdir -p cat-vs-dog-val/$c\n",
    "    for j in `ls $i/*.jpg | shuf | head -n 100`; do\n",
    "        mv $j cat-vs-dog-val/$c/\n",
    "    done\n",
    "done\n",
    "\n",
    "#比原文多了一个test数据集\n",
    "mkdir -p cat-vs-dog-test\n",
    "for i in cat-vs-dog/*; do\n",
    "    c=`basename $i`\n",
    "    mkdir -p cat-vs-dog-test/$c\n",
    "    for j in `ls $i/*.jpg | shuf | head -n 100`; do\n",
    "        mv $j cat-vs-dog-test/$c/\n",
    "    done\n",
    "done\n",
    "\n",
    "mv cat-vs-dog cat-vs-dog-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool for creating lst file\n",
    "!wget -q https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python im2rec.py --list --recursive cat-vs-dog-train cat-vs-dog-train/\n",
    "python im2rec.py --list --recursive cat-vs-dog-val cat-vs-dog-val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 3 ./cat-vs-dog-train.lst > example.lst\n",
    "f = open('example.lst','r')\n",
    "lst_content = f.read()\n",
    "print(lst_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four channels: train, validation, train_lst, and validation_lst\n",
    "s3train = 's3://{}/image-classification/cat-vs-dog/train/'.format(bucket)\n",
    "s3validation = 's3://{}/image-classification/cat-vs-dog/validation/'.format(bucket)\n",
    "s3train_lst = 's3://{}/image-classification/cat-vs-dog/train_lst/'.format(bucket)\n",
    "s3validation_lst = 's3://{}/image-classification/cat-vs-dog/validation_lst/'.format(bucket)\n",
    "\n",
    "# upload the image files to train and validation channels\n",
    "!aws s3 cp cat-vs-dog-train $s3train --recursive --quiet\n",
    "!aws s3 cp cat-vs-dog-val $s3validation --recursive --quiet\n",
    "\n",
    "# upload the lst files to train_lst and validation_lst channels\n",
    "!aws s3 cp cat-vs-dog-train.lst $s3train_lst --quiet\n",
    "!aws s3 cp cat-vs-dog-val.lst $s3validation_lst --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像分类模型的微调\n",
    "### 训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "# The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n",
    "# For this training, we will use 18 layers\n",
    "num_layers = 18\n",
    "# we need to specify the input image shape for the training data\n",
    "image_shape = \"3,224,224\"\n",
    "# we also need to specify the number of training samples in the training set\n",
    "num_training_samples = 15240\n",
    "# specify the number of output classes\n",
    "num_classes = 257\n",
    "# batch size for training\n",
    "mini_batch_size = 128\n",
    "# number of epochs\n",
    "epochs = 6\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "# report top_5 accuracy\n",
    "top_k = 5\n",
    "# resize image before training\n",
    "resize = 256\n",
    "# period to store model parameters (in number of epochs), in this case, we will save parameters from epoch 2, 4, and 6\n",
    "checkpoint_frequency = 2\n",
    "# Since we are using transfer learning, we set use_pretrained_model to 1 so that weights can be \n",
    "# initialized with pre-trained weights\n",
    "use_pretrained_model = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "# create unique job name \n",
    "job_name_prefix = 'sagemaker-imageclassification-notebook'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "training_params = \\\n",
    "{\n",
    "    # specify the training docker image\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/{}/output'.format(bucket, job_name_prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p3.2xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"EnableManagedSpotTraining\": True,\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"image_shape\": image_shape,\n",
    "        \"num_layers\": str(num_layers),\n",
    "        \"num_training_samples\": str(num_training_samples),\n",
    "        \"num_classes\": str(num_classes),\n",
    "        \"mini_batch_size\": str(mini_batch_size),\n",
    "        \"epochs\": str(epochs),\n",
    "        \"learning_rate\": str(learning_rate),\n",
    "        \"top_k\": str(top_k),\n",
    "        \"resize\": str(resize),\n",
    "        \"checkpoint_frequency\": str(checkpoint_frequency),\n",
    "        \"use_pretrained_model\": str(use_pretrained_model)    \n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 360000,\n",
    "        \"MaxWaitTimeInSeconds\": 360000\n",
    "    },\n",
    "#Training data should be inside a subdirectory called \"train\"\n",
    "#Validation data should be inside a subdirectory called \"validation\"\n",
    "#The algorithm currently only supports fullyreplicated model (where data is copied onto each machine)\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3train,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3validation,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"train_lst\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3train_lst,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation_lst\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3validation_lst,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "print('Training job name: {}'.format(job_name))\n",
    "print('\\nInput Data Location: {}'.format(training_params['InputDataConfig'][0]['DataSource']['S3DataSource']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Amazon SageMaker training job\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "sagemaker.create_training_job(**training_params)\n",
    "\n",
    "# confirm that the training job has started\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    # wait for the job to finish and report the ending status\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = training_info['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "     # if exception is raised, that means it has failed\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "status = training_info['TrainingJobStatus']\n",
    "print(\"Training job ended with status: \" + status)\n",
    "print (training_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果看到,\n",
    "\n",
    "> `Training job ended with status: Completed`\n",
    "\n",
    "这意味着训练成功完成，输出模型存储在`training_params['OutputDataConfig']`指定的输出路径中。\n",
    "\n",
    "您还可以使用AWS SageMaker控制台查看有关训练作业的信息和状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 部署模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sage = boto3.Session().client(service_name='sagemaker') \n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name=\"image-classification-model\" + timestamp\n",
    "print(model_name)\n",
    "info = sage.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "hosting_image = retrieve('image-classification',boto3.Session().region_name)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': hosting_image,\n",
    "    'ModelDataUrl': model_data,\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建终端节点配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = job_name_prefix + '-epc-' + timestamp\n",
    "endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.t2.medium',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建终端节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = job_name_prefix + '-ep-' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = sagemaker.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建终端节点大概需要10-15分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the status of the endpoint\n",
    "response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print('EndpointStatus = {}'.format(status))\n",
    "    \n",
    "try:\n",
    "    sagemaker.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "finally:\n",
    "    resp = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Arn: \" + resp['EndpointArn'])\n",
    "    print(\"Create endpoint ended with status: \" + status)\n",
    "\n",
    "    if status != 'InService':\n",
    "        message = sagemaker.describe_endpoint(EndpointName=endpoint_name)['FailureReason']\n",
    "        print('Training failed with the following error: {}'.format(message))\n",
    "        raise Exception('Endpoint creation did not succeed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果看到,\n",
    "\n",
    "> `Create endpoint ended with status: InService`\n",
    "\n",
    "那恭喜你！现在有了一个正常的推理终端节点。您可以导航到AWS SageMaker控制台中的“终端节点”选项卡来确认终端节点配置和状态。\n",
    "\n",
    "\n",
    "最后，我们将创建一个运行时对象，从中可以调用端点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 进行推理\n",
    "\n",
    "最后，客户现在可以验证模型以供使用。可以使用先前操作的结果从中获取终端节点，并使用该端点从经过训练的模型中生成分类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "runtime = boto3.Session().client(service_name='runtime.sagemaker') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cat_test_dir='./cat-vs-dog-test/cat/'\n",
    "files = os.listdir(cat_test_dir)\n",
    "file_name = os.path.join(os.path.join(cat_test_dir, files[0]))\n",
    "# test image\n",
    "from IPython.display import Image\n",
    "Image(file_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/x-image', \n",
    "                                   Body=payload)\n",
    "result = response['Body'].read()\n",
    "# result will be in json format and convert it to ndarray\n",
    "result = json.loads(result)\n",
    "# the result will output the probabilities for all classes\n",
    "# find the class with maximum probability and print the class index\n",
    "index = np.argmax(result)\n",
    "object_categories = ['cat','dog']\n",
    "print(\"Result: label - \" + object_categories[index] + \", probability - \" + str(result[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 清理\n",
    "\n",
    "当我们处理完终端节点之后，我们可以删除它，然后释放后台实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
