{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5 on SageMaker--数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 说明\n",
    "本章内容主要是把labelme数据格式转化为YOLOv5格式。\n",
    "## 2 运行环境\n",
    "Kernel 选择pytorch_latest_p36。 \n",
    "## 3 已有YOLOv5格式数据\n",
    "如果已有YOLOv5格式的数据，可跳过数据准备，把数据放入S3即可。  \n",
    "### 3.1 S3目录存放格式\n",
    "```\n",
    "training\n",
    "├── cfg\n",
    "│   └── data.yaml\n",
    "├── images\n",
    "│   ├── train\n",
    "│   │   ├── image001.jpg\n",
    "│   │   ├── image002.jpg\n",
    "│   │   └── ...\n",
    "│   └── val\n",
    "│       ├── image101.jpg\n",
    "│       ├── image102.jpg\n",
    "│       └── ...\n",
    "└── labels\n",
    "    ├── train\n",
    "    │   ├── image001.txt\n",
    "    │   ├── image002.txt\n",
    "    │   └── ...\n",
    "    └── val\n",
    "        ├── image101.txt\n",
    "        ├── image102.txt\n",
    "        └── ...\n",
    "```\n",
    "### 3.2 SageMaker输入数据根目录\n",
    "运行SageMaker时，SageMaker会从S3拷贝数据放到到运行容器的`/opt/ml/input/data/training/`下。即`data.yaml`对应全路径为`/opt/ml/input/data/training/cfg/data.yaml`\n",
    "### 3.3 文件说明\n",
    "- cfg/data.yaml YOLOv5 train --data的值，必须使用该名称\n",
    "- images/*.jpg 需要训练的图片，分训练目录和验证目录\n",
    "- labels/*.jpg YOLOv5 txt数据\n",
    "\n",
    "### 3.4 YOLOv5 txt数据示例\n",
    "```\n",
    "45 0.736516 0.247188 0.498875 0.476417\n",
    "50 0.637063 0.732938 0.494125 0.510583\n",
    "```\n",
    "第1列为name索引，后4列为标注范围，为xywh格式，即中心点位置(xy)和宽高(wh)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 没有YOLOv5格式数据\n",
    "### 4.1 准备labelme格式数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://nowfox/data/yumaoqiu-labelme.zip ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qo yumaoqiu-labelme.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 创建输出目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"training\"\n",
    "data_types=[\"images\",\"labels\"]\n",
    "stage_types=[\"train\",\"val\"]\n",
    "if os.path.isdir(data_dir):\n",
    "    shutil.rmtree(data_dir)\n",
    "for data_type in data_types:\n",
    "    for stage_type in stage_types:\n",
    "        os.makedirs(os.path.join(data_dir,data_type,stage_type))\n",
    "cfg_dir=os.path.join(data_dir,\"cfg\")\n",
    "os.makedirs(cfg_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 设置names\n",
    "根据自身业务，设置names，其他内容不用修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "names=[\"faqiu\",\"jianqiu\",\"jiqiu\",\"serve_down\",\"serve_up\",\"pickup\",\"play_up\",\"play_down\"]\n",
    "\n",
    "data={}\n",
    "data[\"train\"]=\"/opt/ml/input/data/training/images/train/\"\n",
    "data[\"val\"]=\"/opt/ml/input/data/training/images/val/\"\n",
    "data[\"names\"]=names\n",
    "data[\"nc\"]=len(names)\n",
    "\n",
    "yaml_filename=\"data.yaml\"\n",
    "yaml_file=os.path.join(cfg_dir,yaml_filename)\n",
    "file = open(yaml_file, 'w', encoding='utf-8')\n",
    "yaml.dump(data, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置各个name的索引\n",
    "name_index={}\n",
    "index=0\n",
    "for name in names:\n",
    "    name_index[name]=index\n",
    "    index+=1\n",
    "name_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 转化格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xyxy转xywh\n",
    "def xyxy2xywh(xyxy,width,height):\n",
    "    xywh = []\n",
    "    xywh.append(((xyxy[0]+xyxy[2])/2)/width)\n",
    "    xywh.append(((xyxy[1]+xyxy[3])/2)/height)\n",
    "    xywh.append((xyxy[2]-xyxy[0])/width)\n",
    "    xywh.append((xyxy[3]-xyxy[1])/height)\n",
    "    return xywh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def convert_format(source_json,stage_type):\n",
    "    source_index=source_json.rindex(\"/\")\n",
    "    source_path=source_json[:source_index]\n",
    "    source_file_name=source_json[source_index+1:]\n",
    "    label_output_dir=os.path.join(data_dir,data_types[1],stage_type)\n",
    "    image_output_dir=os.path.join(data_dir,data_types[0],stage_type)\n",
    "    with open(source_json,'r',encoding='utf8')as f:\n",
    "        json_data = json.load(f)\n",
    "    width=json_data[\"imageWidth\"]\n",
    "    height=json_data[\"imageHeight\"]\n",
    "    xywh_result=[]\n",
    "    for shape in json_data[\"shapes\"]:\n",
    "        label=shape[\"label\"]\n",
    "        xyxy=[shape[\"points\"][0][0],shape[\"points\"][0][1],shape[\"points\"][1][0],shape[\"points\"][1][1]]\n",
    "        xywh=xyxy2xywh(xyxy,width,height)\n",
    "        xywh_result.append(('%g ' * 5 ) % (name_index[label], *xywh))\n",
    "    result_txt=os.path.join(label_output_dir,source_file_name.split(\".\")[0]+\".txt\")\n",
    "    with open(result_txt, 'w', encoding='utf-8') as f:\n",
    "        for xywh_line in xywh_result:\n",
    "            f.write(xywh_line)\n",
    "            f.write(\"\\n\")\n",
    "    sourece_img=os.path.join(source_path,json_data[\"imagePath\"])\n",
    "    result_img=os.path.join(image_output_dir,json_data[\"imagePath\"])\n",
    "    shutil.copyfile(sourece_img,result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置需要转化的目录\n",
    "input_dir=\"biaozhu\"\n",
    "json_files=[]\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    if root.find(\".ipynb_checkpoints\")==-1:\n",
    "        for f in files:\n",
    "            if f.endswith(\".json\"):\n",
    "                json_files.append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#根据自身情况设置验证集的比例val_rate\n",
    "val_rate=0.1\n",
    "files_count=len(json_files)\n",
    "val_count=int(files_count*val_rate)\n",
    "random.shuffle(json_files)\n",
    "val_json_files=json_files[:val_count]\n",
    "train_json_files=json_files[val_count:]\n",
    "print(\"总JSON文件数：\"+str(len(json_files)))\n",
    "print(\"val JSON文件数：\"+str(len(val_json_files)))\n",
    "print(\"train JSON文件数：\"+str(len(train_json_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_files(files,stage_type):\n",
    "    for file in files:\n",
    "        convert_format(file,stage_type)\n",
    "deal_files(train_json_files,stage_types[0])\n",
    "deal_files(val_json_files,stage_types[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 上传数据到S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据存放S3 bucket和前缀\n",
    "bucket = 'junzhong'\n",
    "pre_key = 'yolov5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive --quiet training/ s3://{bucket}/{pre_key}/training/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 移动结果文件到训练目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "yaml_path=\"../1-training/container/local_test/input/data/training/cfg/\"\n",
    "target_file=os.path.join(yaml_path,yaml_filename)\n",
    "#if os.path.isfile(target_file):\n",
    "#    os.remove(target_file)\n",
    "shutil.move(yaml_file,target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_type in data_types:\n",
    "    current_dir=os.path.join(data_dir,data_type)\n",
    "    print(current_dir)\n",
    "    shutil.move(current_dir,\"../1-training/container/local_test/input/data/training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
